{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3dde421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aww66/.conda/envs/huggingface/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92bc32b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "init model...\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "checkpoint_dir = \"./models/\"\n",
    "checkpoint_name = \"mdistilbert-fr\"\n",
    "model_name = 'distilbert-base-multilingual-cased'\n",
    "\n",
    "\n",
    "data_dir = \"./data/\"\n",
    "output_dir = \"./data/output/\"\n",
    "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_labels = 2\n",
    "\n",
    "print(device_name)\n",
    "\n",
    "LANGS = ['en', 'de', 'ja', 'es', 'fr', 'zh']\n",
    "\n",
    "print(\"init model...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_dir + checkpoint_name, \n",
    "                                                           num_labels=num_labels).to(device_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32cc1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import scipy.stats as stats\n",
    "\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bded164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model, tokenizer, eval_lang):\n",
    "        self.model = model\n",
    "        self.model.eval() # set to evaluation mode\n",
    "        self.tokenizer = tokenizer\n",
    "        self.eval_lang = eval_lang\n",
    "        self.text_input = None\n",
    "        self.true_labels = None\n",
    "        \n",
    "        self.load_data()\n",
    "        self.logits = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        data = pk.load(open(data_dir + f\"clean_{self.eval_lang}_test.pk\", \"rb\"))\n",
    "        self.text_input = data['text']\n",
    "        self.true_labels = data['binary_labels']\n",
    "        \n",
    "    def make_prediction(self):\n",
    "        logits = None\n",
    "        with torch.no_grad():\n",
    "            for batched_inputs in batch(self.text_input, 20):\n",
    "                encoding = self.tokenizer(batched_inputs, \n",
    "                                          truncation=True, \n",
    "                                          padding=True, \n",
    "                                          return_tensors='pt').to(device_name)\n",
    "                batched_logits = self.model(**encoding)[0]\n",
    "                if logits is None:\n",
    "                    logits = batched_logits\n",
    "                else:\n",
    "                    logits = torch.cat((logits, batched_logits), dim=0)\n",
    "        self.logits = logits\n",
    "        return logits\n",
    "    \n",
    "    def evaluate(self):\n",
    "        if self.logits is None:\n",
    "            raise Exception(\"Run prediction first!\")\n",
    "        _, predicted_labels = torch.max(self.logits, dim=1)\n",
    "        predicted_labels = predicted_labels.tolist()\n",
    "        report = classification_report(predicted_labels, self.true_labels, output_dict=True)\n",
    "        report['kendall-tau'], _ = stats.kendalltau(self.true_labels, self.logits[:, 1].tolist())\n",
    "        report['auc'] = roc_auc_score(self.true_labels, self.logits[:, 1].tolist())\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51b88336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_scores = dict()\n",
    "eval_reports = dict()\n",
    "for lang in LANGS:\n",
    "    ev = Evaluator(model, tokenizer, lang)\n",
    "    pred_scores[lang] = ev.make_prediction()\n",
    "    eval_reports[lang] = ev.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f19a2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pred_scores, output_dir + f\"{checkpoint_name}_scores.pt\")\n",
    "pk.dump(eval_reports, open(output_dir + f\"{checkpoint_name}_eval_reports.pk\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998156a1",
   "metadata": {},
   "source": [
    "## study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f06eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics_df = None\n",
    "metrics = ['accuracy', 'auc', 'kendall-tau']\n",
    "for model_lang in ['en', 'fr', 'zh']:\n",
    "    checkpoint_name = f'mdistilbert-{model_lang}'\n",
    "    eval_reports = pk.load(open(output_dir + f\"{checkpoint_name}_eval_reports.pk\", \"rb\"))\n",
    "    df = pd.DataFrame.from_dict(eval_reports, orient='index')\n",
    "    df['model_lang'] = model_lang\n",
    "    df = df.reset_index().rename({\"index\": \"test_lang\"}, axis=1)\n",
    "    if metrics_df is None:\n",
    "        metrics_df = df[['model_lang', 'test_lang', *metrics]].copy()\n",
    "    else:\n",
    "        metrics_df = pd.concat(\n",
    "            (\n",
    "                metrics_df, \n",
    "                df[['model_lang', 'test_lang', *metrics]]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bd35252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"6\" halign=\"left\">auc</th>\n",
       "      <th colspan=\"6\" halign=\"left\">kendall-tau</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_lang</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>ja</th>\n",
       "      <th>zh</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>ja</th>\n",
       "      <th>zh</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>ja</th>\n",
       "      <th>zh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0.7116</td>\n",
       "      <td>0.8838</td>\n",
       "      <td>0.7268</td>\n",
       "      <td>0.7620</td>\n",
       "      <td>0.5860</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.757209</td>\n",
       "      <td>0.951686</td>\n",
       "      <td>0.850235</td>\n",
       "      <td>0.844972</td>\n",
       "      <td>0.731073</td>\n",
       "      <td>0.756772</td>\n",
       "      <td>0.356435</td>\n",
       "      <td>0.625938</td>\n",
       "      <td>0.485349</td>\n",
       "      <td>0.478055</td>\n",
       "      <td>0.320217</td>\n",
       "      <td>0.355830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0.7394</td>\n",
       "      <td>0.7226</td>\n",
       "      <td>0.7808</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>0.5962</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.808079</td>\n",
       "      <td>0.837050</td>\n",
       "      <td>0.873063</td>\n",
       "      <td>0.947676</td>\n",
       "      <td>0.675161</td>\n",
       "      <td>0.735325</td>\n",
       "      <td>0.426929</td>\n",
       "      <td>0.467076</td>\n",
       "      <td>0.516983</td>\n",
       "      <td>0.620380</td>\n",
       "      <td>0.242735</td>\n",
       "      <td>0.326108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh</th>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>0.5094</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>0.8412</td>\n",
       "      <td>0.734220</td>\n",
       "      <td>0.812382</td>\n",
       "      <td>0.808288</td>\n",
       "      <td>0.760685</td>\n",
       "      <td>0.730695</td>\n",
       "      <td>0.912239</td>\n",
       "      <td>0.324577</td>\n",
       "      <td>0.432892</td>\n",
       "      <td>0.427219</td>\n",
       "      <td>0.361253</td>\n",
       "      <td>0.319692</td>\n",
       "      <td>0.571272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy                                               auc  \\\n",
       "test_lang        de      en      es      fr      ja      zh        de   \n",
       "model_lang                                                              \n",
       "en           0.7116  0.8838  0.7268  0.7620  0.5860  0.7026  0.757209   \n",
       "fr           0.7394  0.7226  0.7808  0.8856  0.5962  0.6840  0.808079   \n",
       "zh           0.5848  0.6946  0.5976  0.5094  0.6572  0.8412  0.734220   \n",
       "\n",
       "                                                             kendall-tau  \\\n",
       "test_lang         en        es        fr        ja        zh          de   \n",
       "model_lang                                                                 \n",
       "en          0.951686  0.850235  0.844972  0.731073  0.756772    0.356435   \n",
       "fr          0.837050  0.873063  0.947676  0.675161  0.735325    0.426929   \n",
       "zh          0.812382  0.808288  0.760685  0.730695  0.912239    0.324577   \n",
       "\n",
       "                                                              \n",
       "test_lang         en        es        fr        ja        zh  \n",
       "model_lang                                                    \n",
       "en          0.625938  0.485349  0.478055  0.320217  0.355830  \n",
       "fr          0.467076  0.516983  0.620380  0.242735  0.326108  \n",
       "zh          0.432892  0.427219  0.361253  0.319692  0.571272  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot(metrics_df, index='model_lang', \n",
    "         columns = 'test_lang', \n",
    "         values=metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
