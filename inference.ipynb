{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3dde421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aww66/.conda/envs/huggingface/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92bc32b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "checkpoint_dir = \"./models/\"\n",
    "\n",
    "model_name = 'distilbert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "data_dir = \"./data/\"\n",
    "output_dir = \"./data/output/\"\n",
    "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_labels = 2\n",
    "\n",
    "print(device_name)\n",
    "\n",
    "LANGS = ['en', 'de', 'ja', 'es', 'fr', 'zh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32cc1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import scipy.stats as stats\n",
    "\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bded164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step: could try to implement using pipeline: https://huggingface.co/docs/transformers/v4.25.1/en/main_classes/pipelines#transformers.pipeline\n",
    "class Evaluator:\n",
    "    def __init__(self, model, tokenizer, eval_lang):\n",
    "        self.model = model\n",
    "        self.model.eval() # set to evaluation mode\n",
    "        self.tokenizer = tokenizer\n",
    "        self.eval_lang = eval_lang\n",
    "        self.text_input = None\n",
    "        self.true_labels = None\n",
    "        \n",
    "        self.load_data()\n",
    "        self.logits = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        data = pk.load(open(data_dir + f\"clean_{self.eval_lang}_test.pk\", \"rb\"))\n",
    "        self.text_input = data['text']\n",
    "        self.true_labels = data['binary_labels']\n",
    "        \n",
    "    def make_prediction(self):\n",
    "        logits = None\n",
    "        with torch.no_grad():\n",
    "            for batched_inputs in batch(self.text_input, 20):\n",
    "                encoding = self.tokenizer(batched_inputs, \n",
    "                                          truncation=True, \n",
    "                                          padding=True, \n",
    "                                          return_tensors='pt').to(device_name)\n",
    "                batched_logits = self.model(**encoding)[0]\n",
    "                if logits is None:\n",
    "                    logits = batched_logits\n",
    "                else:\n",
    "                    logits = torch.cat((logits, batched_logits), dim=0)\n",
    "        self.logits = logits\n",
    "        return logits\n",
    "    \n",
    "    def evaluate(self):\n",
    "        if self.logits is None:\n",
    "            raise Exception(\"Run prediction first!\")\n",
    "        _, predicted_labels = torch.max(self.logits, dim=1)\n",
    "        predicted_labels = predicted_labels.tolist()\n",
    "        report = classification_report(predicted_labels, self.true_labels, output_dict=True)\n",
    "        report['kendall-tau'], report['kendall-tau-p-value'] = stats.kendalltau(self.true_labels, self.logits[:, 1].tolist())\n",
    "        report['auc'] = roc_auc_score(self.true_labels, self.logits[:, 1].tolist())\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11626cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model mdistilbert-zh-epoch-6...\n"
     ]
    }
   ],
   "source": [
    "model_lang = 'zh'\n",
    "checkpoint_name = f\"mdistilbert-{model_lang}-epoch-6\" \n",
    "print(f\"init model {checkpoint_name}...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_dir + checkpoint_name, \n",
    "                                                           num_labels=num_labels).to(device_name)\n",
    "pred_scores = dict()\n",
    "eval_reports = dict()\n",
    "for lang in LANGS:\n",
    "    ev = Evaluator(model, tokenizer, lang)\n",
    "    pred_scores[lang] = ev.make_prediction()\n",
    "    eval_reports[lang] = ev.evaluate()\n",
    "torch.save(pred_scores, output_dir + f\"{checkpoint_name}_scores.pt\")\n",
    "pk.dump(eval_reports, open(output_dir + f\"{checkpoint_name}_eval_reports.pk\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d989495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model mdistilbert-es...\n"
     ]
    }
   ],
   "source": [
    "for model_lang in [\n",
    "    'en', 'fr', 'zh', 'de', 'ja', \"es\"\n",
    "]:\n",
    "    checkpoint_name = f\"mdistilbert-{model_lang}\" \n",
    "    print(f\"init model {checkpoint_name}...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(checkpoint_dir + checkpoint_name, \n",
    "                                                               num_labels=num_labels).to(device_name)\n",
    "    pred_scores = dict()\n",
    "    eval_reports = dict()\n",
    "    for lang in LANGS:\n",
    "        ev = Evaluator(model, tokenizer, lang)\n",
    "        pred_scores[lang] = ev.make_prediction()\n",
    "        eval_reports[lang] = ev.evaluate()\n",
    "    torch.save(pred_scores, output_dir + f\"{checkpoint_name}_scores.pt\")\n",
    "    pk.dump(eval_reports, open(output_dir + f\"{checkpoint_name}_eval_reports.pk\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998156a1",
   "metadata": {},
   "source": [
    "## study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8021cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "metrics_df = None\n",
    "metrics = ['accuracy', 'auc', 'kendall-tau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f06eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_lang in LANGS:\n",
    "    checkpoint_name = f'mdistilbert-{model_lang}'\n",
    "    eval_reports = pk.load(open(output_dir + f\"{checkpoint_name}_eval_reports.pk\", \"rb\"))\n",
    "    df = pd.DataFrame.from_dict(eval_reports, orient='index')\n",
    "    df['model_lang'] = model_lang\n",
    "    df = df.reset_index().rename({\"index\": \"test_lang\"}, axis=1)\n",
    "    if metrics_df is None:\n",
    "        metrics_df = df[['model_lang', 'test_lang', *metrics]].copy()\n",
    "    else:\n",
    "        metrics_df = pd.concat(\n",
    "            (\n",
    "                metrics_df, \n",
    "                df[['model_lang', 'test_lang', *metrics]]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bd35252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"6\" halign=\"left\">auc</th>\n",
       "      <th colspan=\"6\" halign=\"left\">kendall-tau</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_lang</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>ja</th>\n",
       "      <th>zh</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>ja</th>\n",
       "      <th>zh</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>ja</th>\n",
       "      <th>zh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.7936</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>0.5832</td>\n",
       "      <td>0.6838</td>\n",
       "      <td>0.954805</td>\n",
       "      <td>0.858742</td>\n",
       "      <td>0.862021</td>\n",
       "      <td>0.813616</td>\n",
       "      <td>0.702889</td>\n",
       "      <td>0.744877</td>\n",
       "      <td>0.630259</td>\n",
       "      <td>0.497137</td>\n",
       "      <td>0.501681</td>\n",
       "      <td>0.434602</td>\n",
       "      <td>0.281159</td>\n",
       "      <td>0.339346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0.7116</td>\n",
       "      <td>0.8838</td>\n",
       "      <td>0.7268</td>\n",
       "      <td>0.7620</td>\n",
       "      <td>0.5860</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.757209</td>\n",
       "      <td>0.951686</td>\n",
       "      <td>0.850235</td>\n",
       "      <td>0.844972</td>\n",
       "      <td>0.731073</td>\n",
       "      <td>0.756772</td>\n",
       "      <td>0.356435</td>\n",
       "      <td>0.625938</td>\n",
       "      <td>0.485349</td>\n",
       "      <td>0.478055</td>\n",
       "      <td>0.320217</td>\n",
       "      <td>0.355830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>0.7334</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.4930</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>0.803325</td>\n",
       "      <td>0.808570</td>\n",
       "      <td>0.949472</td>\n",
       "      <td>0.860608</td>\n",
       "      <td>0.671722</td>\n",
       "      <td>0.728899</td>\n",
       "      <td>0.420342</td>\n",
       "      <td>0.427610</td>\n",
       "      <td>0.622869</td>\n",
       "      <td>0.499723</td>\n",
       "      <td>0.237969</td>\n",
       "      <td>0.317204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0.7394</td>\n",
       "      <td>0.7226</td>\n",
       "      <td>0.7808</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>0.5962</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.808079</td>\n",
       "      <td>0.837050</td>\n",
       "      <td>0.873063</td>\n",
       "      <td>0.947676</td>\n",
       "      <td>0.675161</td>\n",
       "      <td>0.735325</td>\n",
       "      <td>0.426929</td>\n",
       "      <td>0.467076</td>\n",
       "      <td>0.516983</td>\n",
       "      <td>0.620380</td>\n",
       "      <td>0.242735</td>\n",
       "      <td>0.326108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ja</th>\n",
       "      <td>0.6472</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.6242</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.7066</td>\n",
       "      <td>0.719193</td>\n",
       "      <td>0.789165</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.711201</td>\n",
       "      <td>0.935959</td>\n",
       "      <td>0.749267</td>\n",
       "      <td>0.303753</td>\n",
       "      <td>0.400719</td>\n",
       "      <td>0.311117</td>\n",
       "      <td>0.292678</td>\n",
       "      <td>0.604143</td>\n",
       "      <td>0.345430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh</th>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>0.5094</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>0.8412</td>\n",
       "      <td>0.734220</td>\n",
       "      <td>0.812382</td>\n",
       "      <td>0.808288</td>\n",
       "      <td>0.760685</td>\n",
       "      <td>0.730695</td>\n",
       "      <td>0.912239</td>\n",
       "      <td>0.324577</td>\n",
       "      <td>0.432892</td>\n",
       "      <td>0.427219</td>\n",
       "      <td>0.361253</td>\n",
       "      <td>0.319692</td>\n",
       "      <td>0.571272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy                                               auc  \\\n",
       "test_lang        de      en      es      fr      ja      zh        de   \n",
       "model_lang                                                              \n",
       "de           0.8880  0.7936  0.7964  0.7424  0.5832  0.6838  0.954805   \n",
       "en           0.7116  0.8838  0.7268  0.7620  0.5860  0.7026  0.757209   \n",
       "es           0.7334  0.7044  0.8824  0.7726  0.4930  0.6892  0.803325   \n",
       "fr           0.7394  0.7226  0.7808  0.8856  0.5962  0.6840  0.808079   \n",
       "ja           0.6472  0.7132  0.6280  0.6242  0.8676  0.7066  0.719193   \n",
       "zh           0.5848  0.6946  0.5976  0.5094  0.6572  0.8412  0.734220   \n",
       "\n",
       "                                                             kendall-tau  \\\n",
       "test_lang         en        es        fr        ja        zh          de   \n",
       "model_lang                                                                 \n",
       "de          0.858742  0.862021  0.813616  0.702889  0.744877    0.630259   \n",
       "en          0.951686  0.850235  0.844972  0.731073  0.756772    0.356435   \n",
       "es          0.808570  0.949472  0.860608  0.671722  0.728899    0.420342   \n",
       "fr          0.837050  0.873063  0.947676  0.675161  0.735325    0.426929   \n",
       "ja          0.789165  0.724507  0.711201  0.935959  0.749267    0.303753   \n",
       "zh          0.812382  0.808288  0.760685  0.730695  0.912239    0.324577   \n",
       "\n",
       "                                                              \n",
       "test_lang         en        es        fr        ja        zh  \n",
       "model_lang                                                    \n",
       "de          0.497137  0.501681  0.434602  0.281159  0.339346  \n",
       "en          0.625938  0.485349  0.478055  0.320217  0.355830  \n",
       "es          0.427610  0.622869  0.499723  0.237969  0.317204  \n",
       "fr          0.467076  0.516983  0.620380  0.242735  0.326108  \n",
       "ja          0.400719  0.311117  0.292678  0.604143  0.345430  \n",
       "zh          0.432892  0.427219  0.361253  0.319692  0.571272  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot(metrics_df, index='model_lang', \n",
    "         columns = 'test_lang', \n",
    "         values = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9354dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = f'mdistilbert-{model_lang}'\n",
    "for checkpoint_name in ['mdistilbert-zh', 'mdistilbert-zh-epoch-6']:\n",
    "    eval_reports = pk.load(open(output_dir + f\"{checkpoint_name}_eval_reports.pk\", \"rb\"))\n",
    "    df = pd.DataFrame.from_dict(eval_reports, orient='index')\n",
    "    df['checkpoint'] = checkpoint_name\n",
    "    df = df.reset_index().rename({\"index\": \"test_lang\"}, axis=1)\n",
    "    if metrics_df is None:\n",
    "        metrics_df = df[['checkpoint', 'test_lang', *metrics]].copy()\n",
    "    else:\n",
    "        metrics_df = pd.concat(\n",
    "            (\n",
    "                metrics_df, \n",
    "                df[['checkpoint', 'test_lang', *metrics]]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de236719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"6\" halign=\"left\">auc</th>\n",
       "      <th colspan=\"6\" halign=\"left\">kendall-tau</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_lang</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>ja</th>\n",
       "      <th>zh</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>ja</th>\n",
       "      <th>zh</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>ja</th>\n",
       "      <th>zh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checkpoint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mdistilbert-zh</th>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>0.5094</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>0.8412</td>\n",
       "      <td>0.734220</td>\n",
       "      <td>0.812382</td>\n",
       "      <td>0.808288</td>\n",
       "      <td>0.760685</td>\n",
       "      <td>0.730695</td>\n",
       "      <td>0.912239</td>\n",
       "      <td>0.324577</td>\n",
       "      <td>0.432892</td>\n",
       "      <td>0.427219</td>\n",
       "      <td>0.361253</td>\n",
       "      <td>0.319692</td>\n",
       "      <td>0.571272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdistilbert-zh-epoch-6</th>\n",
       "      <td>0.5642</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.6070</td>\n",
       "      <td>0.5444</td>\n",
       "      <td>0.6208</td>\n",
       "      <td>0.8344</td>\n",
       "      <td>0.651526</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>0.745250</td>\n",
       "      <td>0.722617</td>\n",
       "      <td>0.655869</td>\n",
       "      <td>0.903355</td>\n",
       "      <td>0.209982</td>\n",
       "      <td>0.364459</td>\n",
       "      <td>0.339862</td>\n",
       "      <td>0.308498</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.558960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       accuracy                                          \\\n",
       "test_lang                    de      en      es      fr      ja      zh   \n",
       "checkpoint                                                                \n",
       "mdistilbert-zh           0.5848  0.6946  0.5976  0.5094  0.6572  0.8412   \n",
       "mdistilbert-zh-epoch-6   0.5642  0.7026  0.6070  0.5444  0.6208  0.8344   \n",
       "\n",
       "                             auc                                          \\\n",
       "test_lang                     de        en        es        fr        ja   \n",
       "checkpoint                                                                 \n",
       "mdistilbert-zh          0.734220  0.812382  0.808288  0.760685  0.730695   \n",
       "mdistilbert-zh-epoch-6  0.651526  0.763000  0.745250  0.722617  0.655869   \n",
       "\n",
       "                                 kendall-tau                                \\\n",
       "test_lang                     zh          de        en        es        fr   \n",
       "checkpoint                                                                   \n",
       "mdistilbert-zh          0.912239    0.324577  0.432892  0.427219  0.361253   \n",
       "mdistilbert-zh-epoch-6  0.903355    0.209982  0.364459  0.339862  0.308498   \n",
       "\n",
       "                                            \n",
       "test_lang                     ja        zh  \n",
       "checkpoint                                  \n",
       "mdistilbert-zh          0.319692  0.571272  \n",
       "mdistilbert-zh-epoch-6  0.216000  0.558960  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot(metrics_df, index='checkpoint', \n",
    "         columns = 'test_lang', \n",
    "         values = metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
